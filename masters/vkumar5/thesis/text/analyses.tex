In this chapter we present two key analyses introduced in the \mclab toolkit as
part of the \mixten compiler, and are reusable by other compilers built on top
of the \mclab toolkit. The first analysis is the \emph{IntegerOkay} analysis
that identifies the variables in the \matlab program that can be safely
declared as integer in a statically typed target language like \xten, thus
eliminating the performance overhead associated with otherwise necessary double
to integer typecasts. The second analysis, called \emph{isComplex} analysis,
identifies the numerical values in the source \matlab program that are of
complex type, thus enabling support for code generation for programs that
involve complex numerical values.

\section{Safely using integer variables: \emph{IntegerOkay}
Analysis}\label{sec:intok}

In this section we present the \emph{IntegerOkay} analysis to identify
which variables in the source \matlab program can be safely declared to
be of an integer type instead of the default double type. In \matlab all
the variables holding a numerical value are by default of type
\texttt{Double}, which means that by default, in the \xten code
generated from \matlab, all variables are statically declared to be of
\texttt{Double}. However, in languages like \xten, Java and C++, certain
program operations require the variables used to be of an integer type.
A prominent example of such an operation is an array access operation.
An array access requires the variables used to index into the array to
be of an integer type. For example, in a statement like \texttt{x =
A(i,j)}, the variables \texttt{i} and \texttt{j} are required to be of
integer type and result in an error otherwise.

\subsection{Need for declaring variables to be of integer type}

A simple solution to handle this problem in the generated code from
\matlab is to explicitly cast the variable from \texttt{Double} to
\texttt{Long}, whenever it is required to be used as an integer.
However, our experiments showed this approach to be very inefficient.
With this approach, we observed that the C++ programs generated by the
\xten compiler's C++ backend were slow, and often
even slower than the Java code generated by the \xten Java backend for
the same program (which was somewhat surprising). 
The reason for the added slowness in the C++ code was because each
typecast from \texttt{Double} to \texttt{Long} involved an explicit check on the
value of the \texttt{Double} type variable to ensure that it lies in the
64-bit range supported by \texttt{Long}, whereas the cast in Java is
handled by a primitive bytecode cast instruction.   However, even in
Java, extraneous casts clearly hurt performance.
%Note that even though
%\texttt{Double} is also 64-bit, the IEEE 754 floating point data format
%allows the actual value of the data stored in \texttt{Double} to be much
%higher(lower) than the maximum(minimum) value supported by
%\texttt{Long}. 

To solve this problem, we designed and implemented the
\emph{IntegerOkay} analysis that identifies variables that can be
safely declared to be of \texttt{Long} type, thus eliminating the need
for costly typecasting on these variables.

\subsection{Effect on performance}

To understand the effect on performance caused by typecasting consider a
simple example of \xten code shown in listing \ref{lst:dbl_lng_tc} that just loops
over a 2-dimensional array and sets each element \texttt{A(i,j)} to
\texttt{A(i-1,j-1) + A(i+1, j+1)}.
In this example, the
index variables \texttt{i} and \texttt{j} are declared to be of type
\texttt{Double} and are typecast to \texttt{Long} when used for indexing
into the array.   This example reflects the type of \xten code that we
would generate if we do not have the \emph{IntegerOkay} analysis.

Listing \ref{lst:dbl_lng_notc} shows the same example,
but with \texttt{i} and \texttt{j} declared to be \texttt{Long}, and
thus not requiring an explicit typecast. This example reflects the code
that we would be able to generate with a good \emph{IntegerOkay} analysis.

\begin{lstlisting}[caption={Example for using \texttt{Double} variables for
array indexing},label={lst:dbl_lng_tc},language=x10,numbers=none]
static def useDoubles(scale:Double, n:Long){
  val a: Array_2[Double] = 
    new Array_2[Double](Mix10.rand(scale, scale));
  var i:Double = 0; var j:Double = 0; var v:Long = 0;
  for (v=0;v<n;v++){
    for (j=1;j<a.numElems_2-1;j++){
      for (i=1;i<a.numElems_1-1;i++){
        a(i as Long,j as Long) = a(i as Long -1, j as Long -1) + 
         a(i as Long +1, j as Long +1);
      } } } } 
\end{lstlisting}

\begin{lstlisting}[caption={Example for using \texttt{Long} variables for
indexing},label={lst:dbl_lng_notc},language=x10,numbers=none]
static def useLongs(scale:Double, n:Long){
  val a: Array_2[Double] = 
    new Array_2[Double](Mix10.rand(scale, scale));
  var i:Long = 0; var j:Long = 0; var v:Long = 0;
  for (v=0;v<n;v++){
    for (j=1;j<a.numElems_2-1;j++){
      for (i=1;i<a.numElems_1-1;i++){
        a(i, j) = a(i-1, j-1) + a(i+1, j+1);
      } } } }
\end{lstlisting}

\begin{table}[htbp]
\begin{center}
\input{tables/intok.tex}
\caption{Running times (in seconds) for listings \ref{lst:dbl_lng_tc} and
\ref{lst:dbl_lng_notc}, smaller is better}
\label{tab:intoktable}
\end{center}
\end{table}

Table \ref{tab:intoktable} shows running times (in seconds) for these
two examples for different values of input arguments. For the listing
\ref{lst:dbl_lng_tc}, the C++ code generated by the \xten compiler is
nearly 5 times slower as compared to the Java code generated from \xten for
the same example.  Compared to \ref{lst:dbl_lng_notc} it is slower than
the C++ code for this example by almost 20 times. On the other hand,
Java code for the listing \ref{lst:dbl_lng_tc} is nearly 2 times slower
compared to the Java code for the listing \ref{lst:dbl_lng_notc}.  For
the C++ backend, since the C++ compiler does not provide the checks for
\texttt{Double} to \texttt{Long} typecast, it is implemented in the
\xten C++ backend. For the Java backend, \xten relies on these checks
provided by the JVM.  The more efficient implementation of these checks
in the JVM, compared to that in the \xten C++ backend explains for
comparatively lower slowdowns for the Java code. Section
\ref{subsec:intok_perf} gives detailed evaluation of the performance
benefits obtained by using \emph{IntegerOkay} analysis on our benchmark
set.

\subsection{An overview of the \emph{IntegerOkay} Analysis}

The basic idea behind the \emph{IntegerOkay} analysis is that, for each 
variable \verb|x|, if for every use and every definition of \verb|x| in the
program \verb|x| can be safely assumed to be an integer, i.e. its
declaration as an integer does not change the result of the program,
then it can be declared as an integer. Thus, the problem boils down to
answering the question of whether each use or a definition,
\verb|x| can be safely assumed to be an integer.

There are three possible answers to this question: 
\begin{enumerate}

\item \emph{IntegerOkay}: The variable use/def can be safely assumed to be an
integer.  For example, for a definition like \texttt{x = 2.0} or for use
as an array index like \texttt{A(x)}, it is safe to assume that if
\verb|x| was declared to be an integer, this definition or use will not
affect the result of the program. In other words, for this definition or
use of \verb|x|, \verb|x| is \texttt{IntegerOkay}.

\item \emph{Not IntegerOkay}: The variable cannot be an integer type.
For example consider the expression \texttt{x/y}. Here, since the type
of the operands can affect the result of the division operation, it is
unsafe to assume that \verb|x| and \verb|y| can be of integer type for
this particular use. As another example, consider the definition
\texttt{x = 3.14}. Here, since assuming \verb|x| to be an integer will
result in an error, x is not \emph{IntegerOkay}. 

\item \emph{Conditionally IntegerOkay}: The variable \verb|x| can be
an integer if for the use or definition in question, the variables on
which its value depends on, are \emph{IntegerOkay} everywhere in the
program. For example, in a definition like \texttt{x = a+b}, \verb|x|
can be an integer if both \verb|a| and \verb|b| are integers. We say
\verb|x| is conditionally \emph{IntegerOkay} and depends on \verb|a| and
\verb|b|. Note that in this particular use of \verb|a| and \verb|b| (as
operands of the plus operator), since their type does not affect the
result value of the plus operator, \verb|a| and \verb|b| are
\emph{IntegerOkay}.        

\end{enumerate}   

In our \mixten compiler we solve the \emph{IntegerOkay} problem using a
simple fixed-point computation.   For each variable use and definition,
the algorithm initially associates it with one of the three abstract
values above.  
We then compute the fixed-point by iteratively refining the dependency lists
of the conditional variables.  Consider each variable $x$, if every use
and definition of $x$ has been determined to be \emph{IntegerOkay}, then
$x$ is removed from the dependency lists of all the variables that are
\emph{Conditionally IntegerOkay} and depend on $x$.  Once the dependency
list for a particular use or definition of a variable is empty, it is
upgraded to be \emph{IntegerOkay} for that particular use or definition.

If a variable is not \emph{IntegerOkay} at some point in the program or
its dependency list does not become empty for some point in the program
(say, for circular dependency), it cannot be declared as an integer.
Since, every time we declare a variable to be integer, one or more
\emph{Conditionally IntegerOkay} variables might be upgraded to
\emph{IntegerOkay}, we iteratively repeat the process of finding
variables that are \emph{IntegerOkay} at all points in the program,
until we reach a fixed point. Note that since we never downgrade a
variable to \emph{Not IntegerOkay} or \emph{Conditionally IntegerOkay},
our iterative algorithm will always terminate. 


\subsection{The analysis}



\subsection{An example}

Consider the following pseudocode for example:
\begin{verbatim}
/*1*/ x = 3.0;
/*2*/ y = 3.14;
/*3*/ z = x+y;
/*4*/ for (i = 0; i < 5; i++)
/*5*/   y = y+i;
/*6*/ end
\end{verbatim} 

In this example, the initialization step proceeds as follows.  On line
1, \verb|x| is \emph{IntegerOkay} since 3.0 is a \emph{real integer}. On
line 2, \verb|y| is  \emph{Not IntegerOkay}. On line 3, \verb|z| is
\emph{Conditionally IntegerOkay} and depends on \verb|x| and \verb|y|,
whereas \verb|x| and \verb|y| are \emph{IntegerOkay} in their use in the
expression \texttt{x+y}.  On line 4, \verb|i| is \emph{IntegerOkay} in
its definition \texttt{i = 0}, in its use in the expression \texttt{i <
5}, and also in the definition \texttt{i++}. On line 5, \verb|y| is
conditionally \emph{IntegerOkay} and depends on \verb|i| in its
definition and it is \emph{IntegerOkay} in its use in \verb|y+i|.
\verb|i| is \emph{IntegerOkay} in its use in \texttt{y+i}. Note that on
line 5, we do not include \verb|y| in its own dependency list, since if
we say, \verb|y| is conditionally \emph{IntegerOkay} and depends on
\verb|y|, it is safe to declare \verb|y| as integer as long as it does
not have any other dependencies and is \emph{IntegerOkay} everywhere
else in the program. 

The fixed-point solver for this example proceeds as follows.  We look
for variables that are \emph{IntegerOkay} at every point in the program.
\verb|x| and \verb|i| are two such variables and we can declare them to
be an integer. We also remove x from the dependency list of definition
of \verb|z| on line 3, and \verb|i| from the dependency list of
definition of \verb|y| on line 5. Next, we search again and find that
\verb|y| is \emph{IntegerOkay} in its use on line 3 and line 5, and also
in its definition on line 5, however it is {\emph{Not IntegerOkay} in
its definition on line 2 and thus it cannot be declared as an integer.
\verb|z| on line 3 is dependent on \verb|y| and thus it can also not be
declared as an integer. At this point, we have reached a fixed point
since there are no more upgrades. Finally, we declare \verb|x| and
\verb|i| as integers, and \verb|y| and \verb|z| as doubles.   
